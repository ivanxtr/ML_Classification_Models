{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: librosa in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (0.9.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from librosa) (21.3)\n",
      "Requirement already satisfied: decorator>=4.0.10 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from librosa) (4.4.2)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from librosa) (1.8.0)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from librosa) (0.2.2)\n",
      "Requirement already satisfied: audioread>=2.1.5 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from librosa) (2.1.9)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from librosa) (1.21.6)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from librosa) (0.10.3.post1)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from librosa) (1.0.2)\n",
      "Requirement already satisfied: numba>=0.45.1 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from librosa) (0.55.1)\n",
      "Requirement already satisfied: joblib>=0.14 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: pooch>=1.0 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from librosa) (1.6.0)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from numba>=0.45.1->librosa) (41.2.0)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from numba>=0.45.1->librosa) (0.38.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from packaging>=20.0->librosa) (3.0.8)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from pooch>=1.0->librosa) (2.27.1)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from pooch>=1.0->librosa) (1.4.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.12)\n",
      "Requirement already satisfied: six>=1.3 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from scikit-learn>=0.19.1->librosa) (3.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (2.8.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from tensorflow) (4.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: numpy>=1.20 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from tensorflow) (1.21.6)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from tensorflow) (0.25.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from tensorflow) (3.20.1)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from tensorflow) (1.46.0)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorflow) (41.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.6.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/ivanrodriguez/Library/Python/3.8/lib/python/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install librosa\n",
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>age_onset</th>\n",
       "      <th>birthplace</th>\n",
       "      <th>filename</th>\n",
       "      <th>native_language</th>\n",
       "      <th>sex</th>\n",
       "      <th>speakerid</th>\n",
       "      <th>country</th>\n",
       "      <th>file_missing?</th>\n",
       "      <th>native_class</th>\n",
       "      <th>patientId</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>22.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>hardinxveld-giessendam, netherlands</td>\n",
       "      <td>dutch39</td>\n",
       "      <td>dutch</td>\n",
       "      <td>female</td>\n",
       "      <td>1482</td>\n",
       "      <td>netherlands</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ivan62</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>18.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>bilzen, flanders, belgium</td>\n",
       "      <td>dutch4</td>\n",
       "      <td>dutch</td>\n",
       "      <td>male</td>\n",
       "      <td>743</td>\n",
       "      <td>belgium</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ivan64</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>25.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>dordrecht, netherlands</td>\n",
       "      <td>dutch40</td>\n",
       "      <td>dutch</td>\n",
       "      <td>male</td>\n",
       "      <td>1484</td>\n",
       "      <td>netherlands</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ivan64</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>41.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>deventer, netherlands</td>\n",
       "      <td>dutch41</td>\n",
       "      <td>dutch</td>\n",
       "      <td>male</td>\n",
       "      <td>1517</td>\n",
       "      <td>netherlands</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ivan64</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>36.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>schiedam, netherlands</td>\n",
       "      <td>dutch42</td>\n",
       "      <td>dutch</td>\n",
       "      <td>male</td>\n",
       "      <td>1551</td>\n",
       "      <td>netherlands</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ivan64</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>21.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>rotterdam, netherlands</td>\n",
       "      <td>dutch43</td>\n",
       "      <td>dutch</td>\n",
       "      <td>male</td>\n",
       "      <td>1705</td>\n",
       "      <td>netherlands</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ivan64</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>21.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>antwerp, belgium</td>\n",
       "      <td>dutch44</td>\n",
       "      <td>dutch</td>\n",
       "      <td>female</td>\n",
       "      <td>1740</td>\n",
       "      <td>belgium</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ivan64</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>sint niklaas, belgium</td>\n",
       "      <td>dutch45</td>\n",
       "      <td>dutch</td>\n",
       "      <td>male</td>\n",
       "      <td>1742</td>\n",
       "      <td>belgium</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ivan64</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>22.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>hulshout, belgium</td>\n",
       "      <td>dutch46</td>\n",
       "      <td>dutch</td>\n",
       "      <td>female</td>\n",
       "      <td>1743</td>\n",
       "      <td>belgium</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ivan64</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>37.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>gouda, netherlands</td>\n",
       "      <td>dutch47</td>\n",
       "      <td>dutch</td>\n",
       "      <td>female</td>\n",
       "      <td>2115</td>\n",
       "      <td>netherlands</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ivan64</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  age_onset                           birthplace filename  \\\n",
       "314  22.0       10.0  hardinxveld-giessendam, netherlands  dutch39   \n",
       "315  18.0       10.0            bilzen, flanders, belgium   dutch4   \n",
       "316  25.0        9.0               dordrecht, netherlands  dutch40   \n",
       "317  41.0       13.0                deventer, netherlands  dutch41   \n",
       "318  36.0        8.0                schiedam, netherlands  dutch42   \n",
       "319  21.0       11.0               rotterdam, netherlands  dutch43   \n",
       "320  21.0       12.0                     antwerp, belgium  dutch44   \n",
       "321  22.0        2.0                sint niklaas, belgium  dutch45   \n",
       "322  22.0       12.0                    hulshout, belgium  dutch46   \n",
       "323  37.0       11.0                   gouda, netherlands  dutch47   \n",
       "\n",
       "    native_language     sex  speakerid      country  file_missing?  \\\n",
       "314           dutch  female       1482  netherlands          False   \n",
       "315           dutch    male        743      belgium          False   \n",
       "316           dutch    male       1484  netherlands          False   \n",
       "317           dutch    male       1517  netherlands          False   \n",
       "318           dutch    male       1551  netherlands          False   \n",
       "319           dutch    male       1705  netherlands          False   \n",
       "320           dutch  female       1740      belgium          False   \n",
       "321           dutch    male       1742      belgium          False   \n",
       "322           dutch  female       1743      belgium          False   \n",
       "323           dutch  female       2115  netherlands          False   \n",
       "\n",
       "     native_class patientId  Unnamed: 11  \n",
       "314         False    ivan62          NaN  \n",
       "315         False    ivan64          NaN  \n",
       "316         False    ivan64          NaN  \n",
       "317         False    ivan64          NaN  \n",
       "318         False    ivan64          NaN  \n",
       "319         False    ivan64          NaN  \n",
       "320         False    ivan64          NaN  \n",
       "321         False    ivan64          NaN  \n",
       "322         False    ivan64          NaN  \n",
       "323         False    ivan64          NaN  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "metadata = pd.read_csv('./voices_dataset/speakers_all.csv')\n",
    "metadata.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method IndexOpsMixin.value_counts of 0      female\n",
       "1        male\n",
       "2        male\n",
       "3        male\n",
       "4        male\n",
       "        ...  \n",
       "319      male\n",
       "320    female\n",
       "321      male\n",
       "322    female\n",
       "323    female\n",
       "Name: sex, Length: 324, dtype: object>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['sex'].value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([297, 361, 289, ..., -43, -44, -30], dtype=int16)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.io import wavfile as wav\n",
    "audio_file_path = './voices_dataset/recordings_wav/afrikaans1-gain.wav'\n",
    "wave_sample_rate, wave_audio = wav.read(audio_file_path)\n",
    "wave_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extracting MFCC'S for every audio file\n",
    "audio_dataset_path = './voices_dataset/recordings_wav/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extractor(file):\n",
    "    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=128)\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "    \n",
    "    return mfccs_scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "324it [02:03,  2.63it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "### Now we iterate through every audio file and extract features \n",
    "### using Mel-Frequency Cepstral Coefficients\n",
    "extracted_features=[]\n",
    "for index_num,row in tqdm(metadata.iterrows()):\n",
    "    file_name = os.path.join(os.path.abspath(audio_dataset_path),str(row[\"filename\"]) + str('-gain.wav'))\n",
    "    final_class_labels=row[\"patientId\"]\n",
    "    data=features_extractor(file_name)\n",
    "    extracted_features.append([data,final_class_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "### converting extracted_features to pandas dataframe\n",
    "extracted_features_df = pd.DataFrame(extracted_features, columns=['feature', 'patientId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split the dataset into independent and dependent dataset\n",
    "X = np.array(extracted_features_df['feature'].tolist())\n",
    "y = np.array(extracted_features_df['patientId'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(324, 128)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Label encoding\n",
    "y = np.array(pd.get_dummies(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train Test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.9, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 128)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292, 128)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 33)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292, 33)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## number of patietsId\n",
    "num_labels = y.shape[1]\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "### first layer\n",
    "model.add(Dense(200, input_shape=(128,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "### second layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "### third layer\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "### final layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 200)               25800     \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 200)               0         \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 100)               20100     \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 50)                0         \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 33)                1683      \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 33)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 52,633\n",
      "Trainable params: 52,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy', 'mae', 'mse'],\n",
    "  optimizer='adam'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1830 - accuracy: 0.0400 - mae: 0.0580 - mse: 0.0287\n",
      "Epoch 1: val_loss improved from inf to 3.39397, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.1830 - accuracy: 0.0400 - mae: 0.0580 - mse: 0.0287 - val_loss: 3.3940 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2437 - accuracy: 0.0400 - mae: 0.0581 - mse: 0.0293\n",
      "Epoch 2: val_loss improved from 3.39397 to 3.39389, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.2437 - accuracy: 0.0400 - mae: 0.0581 - mse: 0.0293 - val_loss: 3.3939 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2159 - accuracy: 0.1200 - mae: 0.0581 - mse: 0.0289\n",
      "Epoch 3: val_loss improved from 3.39389 to 3.39380, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.2159 - accuracy: 0.1200 - mae: 0.0581 - mse: 0.0289 - val_loss: 3.3938 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.4422 - accuracy: 0.1200 - mae: 0.0581 - mse: 0.0293\n",
      "Epoch 4: val_loss improved from 3.39380 to 3.39371, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.4422 - accuracy: 0.1200 - mae: 0.0581 - mse: 0.0293 - val_loss: 3.3937 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2810 - accuracy: 0.0800 - mae: 0.0583 - mse: 0.0291\n",
      "Epoch 5: val_loss improved from 3.39371 to 3.39361, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.2810 - accuracy: 0.0800 - mae: 0.0583 - mse: 0.0291 - val_loss: 3.3936 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2208 - accuracy: 0.0800 - mae: 0.0581 - mse: 0.0290\n",
      "Epoch 6: val_loss improved from 3.39361 to 3.39351, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.2208 - accuracy: 0.0800 - mae: 0.0581 - mse: 0.0290 - val_loss: 3.3935 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1510 - accuracy: 0.1600 - mae: 0.0573 - mse: 0.0284\n",
      "Epoch 7: val_loss improved from 3.39351 to 3.39342, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.1510 - accuracy: 0.1600 - mae: 0.0573 - mse: 0.0284 - val_loss: 3.3934 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1926 - accuracy: 0.1200 - mae: 0.0577 - mse: 0.0288\n",
      "Epoch 8: val_loss improved from 3.39342 to 3.39333, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 3.1926 - accuracy: 0.1200 - mae: 0.0577 - mse: 0.0288 - val_loss: 3.3933 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2991 - accuracy: 0.0400 - mae: 0.0582 - mse: 0.0294\n",
      "Epoch 9: val_loss improved from 3.39333 to 3.39324, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.2991 - accuracy: 0.0400 - mae: 0.0582 - mse: 0.0294 - val_loss: 3.3932 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2599 - accuracy: 0.1200 - mae: 0.0582 - mse: 0.0291\n",
      "Epoch 10: val_loss improved from 3.39324 to 3.39315, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.2599 - accuracy: 0.1200 - mae: 0.0582 - mse: 0.0291 - val_loss: 3.3932 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1814 - accuracy: 0.1200 - mae: 0.0580 - mse: 0.0289\n",
      "Epoch 11: val_loss improved from 3.39315 to 3.39307, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.1814 - accuracy: 0.1200 - mae: 0.0580 - mse: 0.0289 - val_loss: 3.3931 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1670 - accuracy: 0.0800 - mae: 0.0577 - mse: 0.0286\n",
      "Epoch 12: val_loss improved from 3.39307 to 3.39299, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.1670 - accuracy: 0.0800 - mae: 0.0577 - mse: 0.0286 - val_loss: 3.3930 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2827 - accuracy: 0.0800 - mae: 0.0582 - mse: 0.0292\n",
      "Epoch 13: val_loss improved from 3.39299 to 3.39293, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.2827 - accuracy: 0.0800 - mae: 0.0582 - mse: 0.0292 - val_loss: 3.3929 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2960 - accuracy: 0.1200 - mae: 0.0583 - mse: 0.0291\n",
      "Epoch 14: val_loss improved from 3.39293 to 3.39286, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 3.2960 - accuracy: 0.1200 - mae: 0.0583 - mse: 0.0291 - val_loss: 3.3929 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1210 - accuracy: 0.0800 - mae: 0.0578 - mse: 0.0287\n",
      "Epoch 15: val_loss improved from 3.39286 to 3.39279, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 3.1210 - accuracy: 0.0800 - mae: 0.0578 - mse: 0.0287 - val_loss: 3.3928 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2895 - accuracy: 0.0800 - mae: 0.0582 - mse: 0.0290\n",
      "Epoch 16: val_loss improved from 3.39279 to 3.39272, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.2895 - accuracy: 0.0800 - mae: 0.0582 - mse: 0.0290 - val_loss: 3.3927 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.3466 - accuracy: 0.0000e+00 - mae: 0.0582 - mse: 0.0294\n",
      "Epoch 17: val_loss improved from 3.39272 to 3.39264, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 3.3466 - accuracy: 0.0000e+00 - mae: 0.0582 - mse: 0.0294 - val_loss: 3.3926 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2058 - accuracy: 0.0400 - mae: 0.0580 - mse: 0.0289\n",
      "Epoch 18: val_loss improved from 3.39264 to 3.39257, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 3.2058 - accuracy: 0.0400 - mae: 0.0580 - mse: 0.0289 - val_loss: 3.3926 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2573 - accuracy: 0.0800 - mae: 0.0581 - mse: 0.0291\n",
      "Epoch 19: val_loss improved from 3.39257 to 3.39249, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.2573 - accuracy: 0.0800 - mae: 0.0581 - mse: 0.0291 - val_loss: 3.3925 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2271 - accuracy: 0.1200 - mae: 0.0582 - mse: 0.0289\n",
      "Epoch 20: val_loss improved from 3.39249 to 3.39241, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.2271 - accuracy: 0.1200 - mae: 0.0582 - mse: 0.0289 - val_loss: 3.3924 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1286 - accuracy: 0.0800 - mae: 0.0573 - mse: 0.0288\n",
      "Epoch 21: val_loss improved from 3.39241 to 3.39234, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.1286 - accuracy: 0.0800 - mae: 0.0573 - mse: 0.0288 - val_loss: 3.3923 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2197 - accuracy: 0.0800 - mae: 0.0578 - mse: 0.0290\n",
      "Epoch 22: val_loss improved from 3.39234 to 3.39226, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.2197 - accuracy: 0.0800 - mae: 0.0578 - mse: 0.0290 - val_loss: 3.3923 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1551 - accuracy: 0.0400 - mae: 0.0579 - mse: 0.0288\n",
      "Epoch 23: val_loss improved from 3.39226 to 3.39219, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.1551 - accuracy: 0.0400 - mae: 0.0579 - mse: 0.0288 - val_loss: 3.3922 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1333 - accuracy: 0.1200 - mae: 0.0575 - mse: 0.0285\n",
      "Epoch 24: val_loss improved from 3.39219 to 3.39212, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.1333 - accuracy: 0.1200 - mae: 0.0575 - mse: 0.0285 - val_loss: 3.3921 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.6684 - accuracy: 0.0800 - mae: 0.0582 - mse: 0.0300\n",
      "Epoch 25: val_loss improved from 3.39212 to 3.39204, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.6684 - accuracy: 0.0800 - mae: 0.0582 - mse: 0.0300 - val_loss: 3.3920 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2829 - accuracy: 0.0800 - mae: 0.0582 - mse: 0.0291\n",
      "Epoch 26: val_loss improved from 3.39204 to 3.39196, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.2829 - accuracy: 0.0800 - mae: 0.0582 - mse: 0.0291 - val_loss: 3.3920 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.4752 - accuracy: 0.0400 - mae: 0.0584 - mse: 0.0295\n",
      "Epoch 27: val_loss improved from 3.39196 to 3.39188, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.4752 - accuracy: 0.0400 - mae: 0.0584 - mse: 0.0295 - val_loss: 3.3919 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2703 - accuracy: 0.1200 - mae: 0.0567 - mse: 0.0283\n",
      "Epoch 28: val_loss improved from 3.39188 to 3.39180, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.2703 - accuracy: 0.1200 - mae: 0.0567 - mse: 0.0283 - val_loss: 3.3918 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.3379 - accuracy: 0.1200 - mae: 0.0581 - mse: 0.0297\n",
      "Epoch 29: val_loss improved from 3.39180 to 3.39173, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.3379 - accuracy: 0.1200 - mae: 0.0581 - mse: 0.0297 - val_loss: 3.3917 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1203 - accuracy: 0.0000e+00 - mae: 0.0577 - mse: 0.0286\n",
      "Epoch 30: val_loss improved from 3.39173 to 3.39165, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.1203 - accuracy: 0.0000e+00 - mae: 0.0577 - mse: 0.0286 - val_loss: 3.3917 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1778 - accuracy: 0.1200 - mae: 0.0580 - mse: 0.0290\n",
      "Epoch 31: val_loss improved from 3.39165 to 3.39158, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 3.1778 - accuracy: 0.1200 - mae: 0.0580 - mse: 0.0290 - val_loss: 3.3916 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1862 - accuracy: 0.1200 - mae: 0.0578 - mse: 0.0289\n",
      "Epoch 32: val_loss improved from 3.39158 to 3.39151, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.1862 - accuracy: 0.1200 - mae: 0.0578 - mse: 0.0289 - val_loss: 3.3915 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2062 - accuracy: 0.1200 - mae: 0.0581 - mse: 0.0289\n",
      "Epoch 33: val_loss improved from 3.39151 to 3.39144, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.2062 - accuracy: 0.1200 - mae: 0.0581 - mse: 0.0289 - val_loss: 3.3914 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.4205 - accuracy: 0.0800 - mae: 0.0582 - mse: 0.0292\n",
      "Epoch 34: val_loss improved from 3.39144 to 3.39138, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 3.4205 - accuracy: 0.0800 - mae: 0.0582 - mse: 0.0292 - val_loss: 3.3914 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2222 - accuracy: 0.1200 - mae: 0.0581 - mse: 0.0289\n",
      "Epoch 35: val_loss improved from 3.39138 to 3.39132, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.2222 - accuracy: 0.1200 - mae: 0.0581 - mse: 0.0289 - val_loss: 3.3913 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1980 - accuracy: 0.1200 - mae: 0.0581 - mse: 0.0289\n",
      "Epoch 36: val_loss improved from 3.39132 to 3.39126, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 3.1980 - accuracy: 0.1200 - mae: 0.0581 - mse: 0.0289 - val_loss: 3.3913 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2094 - accuracy: 0.0800 - mae: 0.0579 - mse: 0.0289\n",
      "Epoch 37: val_loss improved from 3.39126 to 3.39120, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.2094 - accuracy: 0.0800 - mae: 0.0579 - mse: 0.0289 - val_loss: 3.3912 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.0596 - accuracy: 0.1200 - mae: 0.0574 - mse: 0.0284\n",
      "Epoch 38: val_loss improved from 3.39120 to 3.39114, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.0596 - accuracy: 0.1200 - mae: 0.0574 - mse: 0.0284 - val_loss: 3.3911 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1534 - accuracy: 0.1600 - mae: 0.0575 - mse: 0.0286\n",
      "Epoch 39: val_loss improved from 3.39114 to 3.39108, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.1534 - accuracy: 0.1600 - mae: 0.0575 - mse: 0.0286 - val_loss: 3.3911 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1934 - accuracy: 0.0800 - mae: 0.0580 - mse: 0.0289\n",
      "Epoch 40: val_loss improved from 3.39108 to 3.39101, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.1934 - accuracy: 0.0800 - mae: 0.0580 - mse: 0.0289 - val_loss: 3.3910 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1716 - accuracy: 0.1200 - mae: 0.0578 - mse: 0.0287\n",
      "Epoch 41: val_loss improved from 3.39101 to 3.39095, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.1716 - accuracy: 0.1200 - mae: 0.0578 - mse: 0.0287 - val_loss: 3.3909 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.0664 - accuracy: 0.1600 - mae: 0.0569 - mse: 0.0283\n",
      "Epoch 42: val_loss improved from 3.39095 to 3.39088, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.0664 - accuracy: 0.1600 - mae: 0.0569 - mse: 0.0283 - val_loss: 3.3909 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2250 - accuracy: 0.1600 - mae: 0.0580 - mse: 0.0288\n",
      "Epoch 43: val_loss improved from 3.39088 to 3.39081, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 3.2250 - accuracy: 0.1600 - mae: 0.0580 - mse: 0.0288 - val_loss: 3.3908 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1536 - accuracy: 0.1200 - mae: 0.0579 - mse: 0.0288\n",
      "Epoch 44: val_loss improved from 3.39081 to 3.39074, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.1536 - accuracy: 0.1200 - mae: 0.0579 - mse: 0.0288 - val_loss: 3.3907 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1436 - accuracy: 0.1200 - mae: 0.0579 - mse: 0.0288\n",
      "Epoch 45: val_loss improved from 3.39074 to 3.39068, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.1436 - accuracy: 0.1200 - mae: 0.0579 - mse: 0.0288 - val_loss: 3.3907 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2322 - accuracy: 0.0400 - mae: 0.0581 - mse: 0.0291\n",
      "Epoch 46: val_loss improved from 3.39068 to 3.39063, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.2322 - accuracy: 0.0400 - mae: 0.0581 - mse: 0.0291 - val_loss: 3.3906 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2589 - accuracy: 0.0400 - mae: 0.0582 - mse: 0.0291\n",
      "Epoch 47: val_loss improved from 3.39063 to 3.39057, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.2589 - accuracy: 0.0400 - mae: 0.0582 - mse: 0.0291 - val_loss: 3.3906 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.0114 - accuracy: 0.2000 - mae: 0.0567 - mse: 0.0277\n",
      "Epoch 48: val_loss improved from 3.39057 to 3.39051, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.0114 - accuracy: 0.2000 - mae: 0.0567 - mse: 0.0277 - val_loss: 3.3905 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1572 - accuracy: 0.1200 - mae: 0.0571 - mse: 0.0283\n",
      "Epoch 49: val_loss improved from 3.39051 to 3.39045, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.1572 - accuracy: 0.1200 - mae: 0.0571 - mse: 0.0283 - val_loss: 3.3905 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1447 - accuracy: 0.1200 - mae: 0.0576 - mse: 0.0285\n",
      "Epoch 50: val_loss improved from 3.39045 to 3.39040, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.1447 - accuracy: 0.1200 - mae: 0.0576 - mse: 0.0285 - val_loss: 3.3904 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Training completed in time:  0:00:03.116287\n"
     ]
    }
   ],
   "source": [
    "## Trianing my model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 50\n",
    "num_batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/audio_classification.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "history = model.fit(\n",
    "  X_train,\n",
    "  y_train,\n",
    "  batch_size=num_batch_size,\n",
    "  epochs=num_epochs,\n",
    "  validation_data=(X_test, y_test),\n",
    "  callbacks=[checkpointer],\n",
    "  verbose=1,\n",
    "  validation_split = 0.2\n",
    ")\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.577434778213501,\n",
       " 0.02397260256111622,\n",
       " 0.05879722163081169,\n",
       " 0.02952713891863823]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy = model.evaluate(X_test, y_test, verbose = 0)\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>3.232243</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.058130</td>\n",
       "      <td>0.029084</td>\n",
       "      <td>3.390629</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.058507</td>\n",
       "      <td>0.029235</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>3.258854</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.058237</td>\n",
       "      <td>0.029094</td>\n",
       "      <td>3.390570</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.058506</td>\n",
       "      <td>0.029235</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>3.011408</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.056690</td>\n",
       "      <td>0.027749</td>\n",
       "      <td>3.390509</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.058506</td>\n",
       "      <td>0.029235</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>3.157231</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.057105</td>\n",
       "      <td>0.028336</td>\n",
       "      <td>3.390454</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.058506</td>\n",
       "      <td>0.029235</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3.144669</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.057616</td>\n",
       "      <td>0.028495</td>\n",
       "      <td>3.390399</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.058505</td>\n",
       "      <td>0.029235</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy       mae       mse  val_loss  val_accuracy   val_mae  \\\n",
       "45  3.232243      0.04  0.058130  0.029084  3.390629      0.142857  0.058507   \n",
       "46  3.258854      0.04  0.058237  0.029094  3.390570      0.142857  0.058506   \n",
       "47  3.011408      0.20  0.056690  0.027749  3.390509      0.142857  0.058506   \n",
       "48  3.157231      0.12  0.057105  0.028336  3.390454      0.142857  0.058506   \n",
       "49  3.144669      0.12  0.057616  0.028495  3.390399      0.142857  0.058505   \n",
       "\n",
       "     val_mse  epoch  \n",
       "45  0.029235     45  \n",
       "46  0.029235     46  \n",
       "47  0.029235     47  \n",
       "48  0.029235     48  \n",
       "49  0.029235     49  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):     \n",
    "  hist = pd.DataFrame(history.history)\n",
    "  hist['epoch'] = history.epoch\n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Mean Square Error')\n",
    "  plt.plot(hist['epoch'], hist['mse'],'r--',\n",
    "           label='Training Error')\n",
    "  plt.plot(hist['epoch'], hist['val_mse'],'b',\n",
    "           label = 'Validation Error')\n",
    "  plt.ylim([0,20])\n",
    "  plt.legend()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1623 - accuracy: 0.0400 - mae: 0.0579 - mse: 0.0290\n",
      "Epoch 1: val_loss improved from 3.39040 to 3.39034, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 3.1623 - accuracy: 0.0400 - mae: 0.0579 - mse: 0.0290 - val_loss: 3.3903 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2733 - accuracy: 0.0800 - mae: 0.0581 - mse: 0.0291\n",
      "Epoch 2: val_loss improved from 3.39034 to 3.39029, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.2733 - accuracy: 0.0800 - mae: 0.0581 - mse: 0.0291 - val_loss: 3.3903 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2609 - accuracy: 0.0400 - mae: 0.0582 - mse: 0.0297\n",
      "Epoch 3: val_loss improved from 3.39029 to 3.39023, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.2609 - accuracy: 0.0400 - mae: 0.0582 - mse: 0.0297 - val_loss: 3.3902 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2663 - accuracy: 0.0400 - mae: 0.0582 - mse: 0.0295\n",
      "Epoch 4: val_loss improved from 3.39023 to 3.39018, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.2663 - accuracy: 0.0400 - mae: 0.0582 - mse: 0.0295 - val_loss: 3.3902 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.0722 - accuracy: 0.1200 - mae: 0.0575 - mse: 0.0285\n",
      "Epoch 5: val_loss improved from 3.39018 to 3.39015, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.0722 - accuracy: 0.1200 - mae: 0.0575 - mse: 0.0285 - val_loss: 3.3901 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.3744 - accuracy: 0.0800 - mae: 0.0584 - mse: 0.0302\n",
      "Epoch 6: val_loss improved from 3.39015 to 3.39009, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.3744 - accuracy: 0.0800 - mae: 0.0584 - mse: 0.0302 - val_loss: 3.3901 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1900 - accuracy: 0.0400 - mae: 0.0580 - mse: 0.0289\n",
      "Epoch 7: val_loss improved from 3.39009 to 3.39004, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 3.1900 - accuracy: 0.0400 - mae: 0.0580 - mse: 0.0289 - val_loss: 3.3900 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.0061 - accuracy: 0.1600 - mae: 0.0560 - mse: 0.0278\n",
      "Epoch 8: val_loss improved from 3.39004 to 3.39000, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 3.0061 - accuracy: 0.1600 - mae: 0.0560 - mse: 0.0278 - val_loss: 3.3900 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1849 - accuracy: 0.1600 - mae: 0.0580 - mse: 0.0291\n",
      "Epoch 9: val_loss improved from 3.39000 to 3.38995, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.1849 - accuracy: 0.1600 - mae: 0.0580 - mse: 0.0291 - val_loss: 3.3900 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1261 - accuracy: 0.1200 - mae: 0.0578 - mse: 0.0287\n",
      "Epoch 10: val_loss improved from 3.38995 to 3.38991, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.1261 - accuracy: 0.1200 - mae: 0.0578 - mse: 0.0287 - val_loss: 3.3899 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.0095 - accuracy: 0.1200 - mae: 0.0565 - mse: 0.0279\n",
      "Epoch 11: val_loss improved from 3.38991 to 3.38986, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.0095 - accuracy: 0.1200 - mae: 0.0565 - mse: 0.0279 - val_loss: 3.3899 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1828 - accuracy: 0.1600 - mae: 0.0566 - mse: 0.0280\n",
      "Epoch 12: val_loss improved from 3.38986 to 3.38980, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.1828 - accuracy: 0.1600 - mae: 0.0566 - mse: 0.0280 - val_loss: 3.3898 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.4147 - accuracy: 0.0800 - mae: 0.0582 - mse: 0.0295\n",
      "Epoch 13: val_loss improved from 3.38980 to 3.38976, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.4147 - accuracy: 0.0800 - mae: 0.0582 - mse: 0.0295 - val_loss: 3.3898 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2507 - accuracy: 0.1600 - mae: 0.0574 - mse: 0.0287\n",
      "Epoch 14: val_loss improved from 3.38976 to 3.38973, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.2507 - accuracy: 0.1600 - mae: 0.0574 - mse: 0.0287 - val_loss: 3.3897 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1194 - accuracy: 0.1200 - mae: 0.0577 - mse: 0.0287\n",
      "Epoch 15: val_loss improved from 3.38973 to 3.38970, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.1194 - accuracy: 0.1200 - mae: 0.0577 - mse: 0.0287 - val_loss: 3.3897 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.0931 - accuracy: 0.1600 - mae: 0.0570 - mse: 0.0282\n",
      "Epoch 16: val_loss improved from 3.38970 to 3.38966, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.0931 - accuracy: 0.1600 - mae: 0.0570 - mse: 0.0282 - val_loss: 3.3897 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2739 - accuracy: 0.1200 - mae: 0.0581 - mse: 0.0291\n",
      "Epoch 17: val_loss improved from 3.38966 to 3.38961, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.2739 - accuracy: 0.1200 - mae: 0.0581 - mse: 0.0291 - val_loss: 3.3896 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1563 - accuracy: 0.2000 - mae: 0.0574 - mse: 0.0287\n",
      "Epoch 18: val_loss improved from 3.38961 to 3.38957, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 3.1563 - accuracy: 0.2000 - mae: 0.0574 - mse: 0.0287 - val_loss: 3.3896 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1533 - accuracy: 0.1200 - mae: 0.0579 - mse: 0.0287\n",
      "Epoch 19: val_loss improved from 3.38957 to 3.38952, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.1533 - accuracy: 0.1200 - mae: 0.0579 - mse: 0.0287 - val_loss: 3.3895 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.0789 - accuracy: 0.0800 - mae: 0.0570 - mse: 0.0281\n",
      "Epoch 20: val_loss improved from 3.38952 to 3.38947, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.0789 - accuracy: 0.0800 - mae: 0.0570 - mse: 0.0281 - val_loss: 3.3895 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2305 - accuracy: 0.0800 - mae: 0.0581 - mse: 0.0289\n",
      "Epoch 21: val_loss improved from 3.38947 to 3.38942, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.2305 - accuracy: 0.0800 - mae: 0.0581 - mse: 0.0289 - val_loss: 3.3894 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2314 - accuracy: 0.0800 - mae: 0.0579 - mse: 0.0290\n",
      "Epoch 22: val_loss improved from 3.38942 to 3.38938, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.2314 - accuracy: 0.0800 - mae: 0.0579 - mse: 0.0290 - val_loss: 3.3894 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2315 - accuracy: 0.0400 - mae: 0.0580 - mse: 0.0292\n",
      "Epoch 23: val_loss improved from 3.38938 to 3.38935, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.2315 - accuracy: 0.0400 - mae: 0.0580 - mse: 0.0292 - val_loss: 3.3894 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2582 - accuracy: 0.1200 - mae: 0.0581 - mse: 0.0291\n",
      "Epoch 24: val_loss improved from 3.38935 to 3.38931, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.2582 - accuracy: 0.1200 - mae: 0.0581 - mse: 0.0291 - val_loss: 3.3893 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.4693 - accuracy: 0.0800 - mae: 0.0583 - mse: 0.0300\n",
      "Epoch 25: val_loss improved from 3.38931 to 3.38924, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.4693 - accuracy: 0.0800 - mae: 0.0583 - mse: 0.0300 - val_loss: 3.3892 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1163 - accuracy: 0.0000e+00 - mae: 0.0578 - mse: 0.0289\n",
      "Epoch 26: val_loss improved from 3.38924 to 3.38916, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.1163 - accuracy: 0.0000e+00 - mae: 0.0578 - mse: 0.0289 - val_loss: 3.3892 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2086 - accuracy: 0.0400 - mae: 0.0580 - mse: 0.0289\n",
      "Epoch 27: val_loss improved from 3.38916 to 3.38908, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.2086 - accuracy: 0.0400 - mae: 0.0580 - mse: 0.0289 - val_loss: 3.3891 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.9584 - accuracy: 0.1200 - mae: 0.0560 - mse: 0.0274\n",
      "Epoch 28: val_loss improved from 3.38908 to 3.38899, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.9584 - accuracy: 0.1200 - mae: 0.0560 - mse: 0.0274 - val_loss: 3.3890 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2160 - accuracy: 0.1200 - mae: 0.0580 - mse: 0.0288\n",
      "Epoch 29: val_loss improved from 3.38899 to 3.38891, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.2160 - accuracy: 0.1200 - mae: 0.0580 - mse: 0.0288 - val_loss: 3.3889 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1208 - accuracy: 0.0400 - mae: 0.0576 - mse: 0.0285\n",
      "Epoch 30: val_loss improved from 3.38891 to 3.38882, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.1208 - accuracy: 0.0400 - mae: 0.0576 - mse: 0.0285 - val_loss: 3.3888 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.0734 - accuracy: 0.0800 - mae: 0.0559 - mse: 0.0277\n",
      "Epoch 31: val_loss improved from 3.38882 to 3.38873, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.0734 - accuracy: 0.0800 - mae: 0.0559 - mse: 0.0277 - val_loss: 3.3887 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1628 - accuracy: 0.0800 - mae: 0.0579 - mse: 0.0289\n",
      "Epoch 32: val_loss improved from 3.38873 to 3.38864, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 3.1628 - accuracy: 0.0800 - mae: 0.0579 - mse: 0.0289 - val_loss: 3.3886 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1936 - accuracy: 0.0400 - mae: 0.0580 - mse: 0.0289\n",
      "Epoch 33: val_loss improved from 3.38864 to 3.38855, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.1936 - accuracy: 0.0400 - mae: 0.0580 - mse: 0.0289 - val_loss: 3.3886 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2440 - accuracy: 0.1200 - mae: 0.0581 - mse: 0.0291\n",
      "Epoch 34: val_loss improved from 3.38855 to 3.38848, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.2440 - accuracy: 0.1200 - mae: 0.0581 - mse: 0.0291 - val_loss: 3.3885 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1766 - accuracy: 0.0800 - mae: 0.0579 - mse: 0.0289\n",
      "Epoch 35: val_loss improved from 3.38848 to 3.38840, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.1766 - accuracy: 0.0800 - mae: 0.0579 - mse: 0.0289 - val_loss: 3.3884 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2386 - accuracy: 0.0400 - mae: 0.0581 - mse: 0.0290\n",
      "Epoch 36: val_loss improved from 3.38840 to 3.38832, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.2386 - accuracy: 0.0400 - mae: 0.0581 - mse: 0.0290 - val_loss: 3.3883 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2181 - accuracy: 0.0400 - mae: 0.0581 - mse: 0.0291\n",
      "Epoch 37: val_loss improved from 3.38832 to 3.38825, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.2181 - accuracy: 0.0400 - mae: 0.0581 - mse: 0.0291 - val_loss: 3.3882 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2461 - accuracy: 0.0000e+00 - mae: 0.0581 - mse: 0.0290\n",
      "Epoch 38: val_loss improved from 3.38825 to 3.38817, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.2461 - accuracy: 0.0000e+00 - mae: 0.0581 - mse: 0.0290 - val_loss: 3.3882 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1774 - accuracy: 0.0800 - mae: 0.0580 - mse: 0.0289\n",
      "Epoch 39: val_loss improved from 3.38817 to 3.38807, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.1774 - accuracy: 0.0800 - mae: 0.0580 - mse: 0.0289 - val_loss: 3.3881 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2723 - accuracy: 0.0800 - mae: 0.0581 - mse: 0.0292\n",
      "Epoch 40: val_loss improved from 3.38807 to 3.38796, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.2723 - accuracy: 0.0800 - mae: 0.0581 - mse: 0.0292 - val_loss: 3.3880 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2155 - accuracy: 0.0000e+00 - mae: 0.0580 - mse: 0.0290\n",
      "Epoch 41: val_loss improved from 3.38796 to 3.38786, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.2155 - accuracy: 0.0000e+00 - mae: 0.0580 - mse: 0.0290 - val_loss: 3.3879 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.3102 - accuracy: 0.0800 - mae: 0.0582 - mse: 0.0294\n",
      "Epoch 42: val_loss improved from 3.38786 to 3.38774, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 3.3102 - accuracy: 0.0800 - mae: 0.0582 - mse: 0.0294 - val_loss: 3.3877 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2849 - accuracy: 0.0400 - mae: 0.0581 - mse: 0.0296\n",
      "Epoch 43: val_loss improved from 3.38774 to 3.38762, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.2849 - accuracy: 0.0400 - mae: 0.0581 - mse: 0.0296 - val_loss: 3.3876 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1178 - accuracy: 0.0400 - mae: 0.0578 - mse: 0.0287\n",
      "Epoch 44: val_loss improved from 3.38762 to 3.38748, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 3.1178 - accuracy: 0.0400 - mae: 0.0578 - mse: 0.0287 - val_loss: 3.3875 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1675 - accuracy: 0.0400 - mae: 0.0580 - mse: 0.0288\n",
      "Epoch 45: val_loss improved from 3.38748 to 3.38733, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 3.1675 - accuracy: 0.0400 - mae: 0.0580 - mse: 0.0288 - val_loss: 3.3873 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1089 - accuracy: 0.1600 - mae: 0.0570 - mse: 0.0280\n",
      "Epoch 46: val_loss improved from 3.38733 to 3.38717, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 3.1089 - accuracy: 0.1600 - mae: 0.0570 - mse: 0.0280 - val_loss: 3.3872 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.0898 - accuracy: 0.0800 - mae: 0.0561 - mse: 0.0279\n",
      "Epoch 47: val_loss improved from 3.38717 to 3.38701, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.0898 - accuracy: 0.0800 - mae: 0.0561 - mse: 0.0279 - val_loss: 3.3870 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1409 - accuracy: 0.1600 - mae: 0.0560 - mse: 0.0283\n",
      "Epoch 48: val_loss improved from 3.38701 to 3.38686, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.1409 - accuracy: 0.1600 - mae: 0.0560 - mse: 0.0283 - val_loss: 3.3869 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1544 - accuracy: 0.0800 - mae: 0.0579 - mse: 0.0291\n",
      "Epoch 49: val_loss improved from 3.38686 to 3.38669, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.1544 - accuracy: 0.0800 - mae: 0.0579 - mse: 0.0291 - val_loss: 3.3867 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.0865 - accuracy: 0.1200 - mae: 0.0571 - mse: 0.0282\n",
      "Epoch 50: val_loss improved from 3.38669 to 3.38652, saving model to saved_models/audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.0865 - accuracy: 0.1200 - mae: 0.0571 - mse: 0.0282 - val_loss: 3.3865 - val_accuracy: 0.1429 - val_mae: 0.0585 - val_mse: 0.0292\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "      monitor='val_loss', patience=10)\n",
    "\n",
    "history = model.fit(\n",
    "  X_train,\n",
    "  y_train,\n",
    "  batch_size=num_batch_size,\n",
    "  epochs=num_epochs,\n",
    "  validation_data=(X_test, y_test),\n",
    "  callbacks=[checkpointer, early_stop],\n",
    "  verbose=1,\n",
    "  validation_split = 0.2\n",
    ")\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### testing the model\n",
    "test_filename = './voices_dataset/recordings_wav/afrikaans1-gain.wav'\n",
    "audio, sample_rate = librosa.load(test_filename, res_type='kaiser_fast')\n",
    "mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=128)\n",
    "mfccs_scaled_features = np.mean(mfccs_features.T, axis=0)\n",
    "# print(mfccs_scaled_features)\n",
    "\n",
    "# using juts one item\n",
    "mfccs_scaled_features = mfccs_scaled_features.reshape(1, -1)\n",
    "#print(mfccs_scaled_features)\n",
    "#print(mfccs_scaled_features.shape)\n",
    "\n",
    "predicted_label = model.predict(mfccs_scaled_features)\n",
    "predicted_classes = np.argmax(predicted_label, axis=1)\n",
    "predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ivan48'], dtype=object)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "y = to_categorical(labelencoder.fit_transform(metadata['patientId']))\n",
    "\n",
    "prediction_class = labelencoder.inverse_transform(predicted_classes)\n",
    "prediction_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>age_onset</th>\n",
       "      <th>birthplace</th>\n",
       "      <th>filename</th>\n",
       "      <th>native_language</th>\n",
       "      <th>sex</th>\n",
       "      <th>speakerid</th>\n",
       "      <th>country</th>\n",
       "      <th>file_missing?</th>\n",
       "      <th>native_class</th>\n",
       "      <th>patientId</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>virginia, south africa</td>\n",
       "      <td>afrikaans1</td>\n",
       "      <td>afrikaans</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>south africa</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>ivan1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>pretoria, south africa</td>\n",
       "      <td>afrikaans2</td>\n",
       "      <td>afrikaans</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>south africa</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>ivan1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>pretoria, transvaal, south africa</td>\n",
       "      <td>afrikaans3</td>\n",
       "      <td>afrikaans</td>\n",
       "      <td>male</td>\n",
       "      <td>418</td>\n",
       "      <td>south africa</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>ivan1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>pretoria, south africa</td>\n",
       "      <td>afrikaans4</td>\n",
       "      <td>afrikaans</td>\n",
       "      <td>male</td>\n",
       "      <td>1159</td>\n",
       "      <td>south africa</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>ivan1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>cape town, south africa</td>\n",
       "      <td>afrikaans5</td>\n",
       "      <td>afrikaans</td>\n",
       "      <td>male</td>\n",
       "      <td>1432</td>\n",
       "      <td>south africa</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>ivan1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>diekabo, ivory coast</td>\n",
       "      <td>agni1</td>\n",
       "      <td>agni</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>ivory coast</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>ivan1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>accra, ghana</td>\n",
       "      <td>akan1</td>\n",
       "      <td>akan</td>\n",
       "      <td>male</td>\n",
       "      <td>979</td>\n",
       "      <td>ghana</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>ivan1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>prishtina, kosovo</td>\n",
       "      <td>albanian1</td>\n",
       "      <td>albanian</td>\n",
       "      <td>male</td>\n",
       "      <td>4</td>\n",
       "      <td>kosovo</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>ivan1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>33.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>tirana, albania</td>\n",
       "      <td>albanian2</td>\n",
       "      <td>albanian</td>\n",
       "      <td>male</td>\n",
       "      <td>5</td>\n",
       "      <td>albania</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>ivan1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>44.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>tirana, albania</td>\n",
       "      <td>albanian3</td>\n",
       "      <td>albanian</td>\n",
       "      <td>male</td>\n",
       "      <td>458</td>\n",
       "      <td>albania</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>ivan1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  age_onset                         birthplace    filename  \\\n",
       "0  27.0        9.0             virginia, south africa  afrikaans1   \n",
       "1  40.0        5.0             pretoria, south africa  afrikaans2   \n",
       "2  43.0        4.0  pretoria, transvaal, south africa  afrikaans3   \n",
       "3  26.0        8.0             pretoria, south africa  afrikaans4   \n",
       "4  19.0        6.0            cape town, south africa  afrikaans5   \n",
       "5  25.0       15.0               diekabo, ivory coast       agni1   \n",
       "6  41.0        5.0                       accra, ghana       akan1   \n",
       "7  19.0        6.0                  prishtina, kosovo   albanian1   \n",
       "8  33.0       15.0                    tirana, albania   albanian2   \n",
       "9  44.0       35.0                    tirana, albania   albanian3   \n",
       "\n",
       "  native_language     sex  speakerid       country  file_missing?  \\\n",
       "0       afrikaans  female          1  south africa          False   \n",
       "1       afrikaans    male          2  south africa          False   \n",
       "2       afrikaans    male        418  south africa          False   \n",
       "3       afrikaans    male       1159  south africa          False   \n",
       "4       afrikaans    male       1432  south africa          False   \n",
       "5            agni    male          3   ivory coast          False   \n",
       "6            akan    male        979         ghana          False   \n",
       "7        albanian    male          4        kosovo          False   \n",
       "8        albanian    male          5       albania          False   \n",
       "9        albanian    male        458       albania          False   \n",
       "\n",
       "   native_class patientId  Unnamed: 11  \n",
       "0          True     ivan1          NaN  \n",
       "1          True     ivan1          NaN  \n",
       "2          True     ivan1          NaN  \n",
       "3          True     ivan1          NaN  \n",
       "4          True     ivan1          NaN  \n",
       "5          True     ivan1          NaN  \n",
       "6          True     ivan1          NaN  \n",
       "7          True     ivan1          NaN  \n",
       "8          True     ivan1          NaN  \n",
       "9          True     ivan1          NaN  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at confusion matrix \n",
    "#Note, this code is taken straight from the SKLEARN website, an nice way of viewing confusion matrix.\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Observacin')\n",
    "    plt.xlabel('Prediccin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(X_test)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_pred, axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(y_test, axis = 1) \n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(3))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
